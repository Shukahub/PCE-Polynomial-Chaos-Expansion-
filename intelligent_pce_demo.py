#!/usr/bin/env python3
"""
æ™ºèƒ½PCEé˜¶æ•°é€‰æ‹©æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ™ºèƒ½é˜¶æ•°é€‰æ‹©åŠŸèƒ½æ¥ä¼˜åŒ–PCEæ¨¡å‹æ€§èƒ½
"""

import numpy as np
import matplotlib.pyplot as plt
import time
from pce_trainer import PCETrainer
from sklearn.metrics import r2_score, mean_squared_error
import seaborn as sns

# è®¾ç½®æ ·å¼
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.dpi'] = 300
sns.set_style("whitegrid")

class IntelligentPCEDemo:
    """æ™ºèƒ½PCEæ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤º"""
        self.test_functions = {}
        self.results = {}
        
    def create_test_functions(self):
        """Create test functions with different complexity levels"""
        print("ğŸ¯ Creating test functions...")

        # 1. Linear function
        def linear_func(x1, x2):
            return 0.5 + 1.2*x1 + 0.8*x2

        # 2. Quadratic function
        def quadratic_func(x1, x2):
            return 0.5 + 1.2*x1 + 0.8*x2 + 0.6*x1**2 + 0.4*x1*x2 + 0.3*x2**2

        # 3. Cubic function
        def cubic_func(x1, x2):
            return (0.5 + x1 + x2 + x1**2 + x1*x2 + x2**2 +
                   0.3*x1**3 + 0.2*x1**2*x2 + 0.1*x1*x2**2 + 0.15*x2**3)

        # 4. Complex nonlinear function
        def complex_func(x1, x2):
            return (np.sin(2*x1) * np.cos(2*x2) +
                   0.3*np.exp(-0.5*(x1**2 + x2**2)) +
                   0.2*np.tanh(3*x1*x2))

        # 5. High-frequency oscillatory function
        def oscillatory_func(x1, x2):
            return (np.sin(5*np.pi*x1) * np.cos(3*np.pi*x2) +
                   0.5*np.sin(8*np.pi*x1*x2) +
                   0.3*(x1**2 + x2**2))

        self.test_functions = {
            "Linear": {
                "func": linear_func,
                "expected_order": 1,
                "description": "Simple linear relationship, PCE should select order 1"
            },
            "Quadratic": {
                "func": quadratic_func,
                "expected_order": 2,
                "description": "Standard quadratic polynomial, PCE should select order 2"
            },
            "Cubic": {
                "func": cubic_func,
                "expected_order": 3,
                "description": "Cubic polynomial, PCE should select order 3"
            },
            "Complex Nonlinear": {
                "func": complex_func,
                "expected_order": 3,
                "description": "Smooth nonlinear, PCE may select order 3-4"
            },
            "High-Frequency": {
                "func": oscillatory_func,
                "expected_order": 4,
                "description": "High-frequency components, PCE may select order 4-5 or suggest other methods"
            }
        }

        print(f"âœ… Created {len(self.test_functions)} test functions")
        
    def generate_data(self, func, n_samples=1000, noise_level=0.01):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        X = np.random.uniform(-1, 1, (n_samples, 2))
        Y = np.array([func(X[i, 0], X[i, 1]) for i in range(n_samples)])
        
        # æ·»åŠ å™ªå£°
        if noise_level > 0:
            Y += np.random.normal(0, noise_level, Y.shape)
        
        return X, Y.reshape(-1, 1)
    
    def test_intelligent_order_selection(self):
        """æµ‹è¯•æ™ºèƒ½é˜¶æ•°é€‰æ‹©"""
        print("\n" + "="*80)
        print("ğŸ§  æ™ºèƒ½PCEé˜¶æ•°é€‰æ‹©æµ‹è¯•")
        print("="*80)
        
        for func_name, func_info in self.test_functions.items():
            print(f"\n{'='*20} {func_name} {'='*20}")
            print(f"ğŸ“ æè¿°: {func_info['description']}")
            print(f"ğŸ¯ æœŸæœ›é˜¶æ•°: {func_info['expected_order']}")
            
            # ç”Ÿæˆæ•°æ®
            X, Y = self.generate_data(func_info['func'], n_samples=1000)
            
            # åˆ›å»ºæ™ºèƒ½PCEè®­ç»ƒå™¨
            trainer = PCETrainer(
                input_dim=2, 
                output_dim=1, 
                polynomial_order=None,  # è‡ªåŠ¨é€‰æ‹©
                auto_order_selection=True
            )
            
            # æµ‹è¯•æ™ºèƒ½é˜¶æ•°é€‰æ‹©
            start_time = time.time()
            optimal_order = trainer.select_optimal_order(X, Y, max_order=5)
            selection_time = time.time() - start_time
            
            # è®­ç»ƒæ¨¡å‹
            start_time = time.time()
            results = trainer.train(X, Y, test_size=0.2)
            training_time = time.time() - start_time
            
            # ä¿å­˜ç»“æœ
            self.results[func_name] = {
                'expected_order': func_info['expected_order'],
                'selected_order': optimal_order,
                'selection_time': selection_time,
                'training_time': training_time,
                'test_r2': results['test_r2'],
                'test_mse': results['test_mse'],
                'order_selection_results': trainer.order_selection_results
            }
            
            # æ˜¾ç¤ºç»“æœ
            print(f"âœ… æ™ºèƒ½é€‰æ‹©ç»“æœ:")
            print(f"   é€‰æ‹©é˜¶æ•°: {optimal_order}")
            print(f"   æœŸæœ›é˜¶æ•°: {func_info['expected_order']}")
            print(f"   é€‰æ‹©å‡†ç¡®: {'âœ…' if optimal_order == func_info['expected_order'] else 'âš ï¸'}")
            print(f"   é€‰æ‹©æ—¶é—´: {selection_time:.3f} ç§’")
            print(f"   è®­ç»ƒæ—¶é—´: {training_time:.3f} ç§’")
            print(f"   æµ‹è¯•RÂ²: {results['test_r2']:.6f}")
            print(f"   æµ‹è¯•MSE: {results['test_mse']:.6f}")
    
    def compare_with_fixed_orders(self):
        """ä¸å›ºå®šé˜¶æ•°è¿›è¡Œå¯¹æ¯”"""
        print("\n" + "="*80)
        print("ğŸ“Š æ™ºèƒ½é€‰æ‹© vs å›ºå®šé˜¶æ•°å¯¹æ¯”")
        print("="*80)
        
        comparison_results = {}
        
        for func_name, func_info in self.test_functions.items():
            print(f"\nğŸ” æµ‹è¯•å‡½æ•°: {func_name}")
            
            X, Y = self.generate_data(func_info['func'], n_samples=1000)
            
            # æµ‹è¯•ä¸åŒå›ºå®šé˜¶æ•°
            fixed_orders = [1, 2, 3, 4, 5]
            fixed_results = {}
            
            for order in fixed_orders:
                try:
                    trainer = PCETrainer(
                        input_dim=2, 
                        output_dim=1, 
                        polynomial_order=order,
                        auto_order_selection=False
                    )
                    
                    start_time = time.time()
                    results = trainer.train(X, Y, test_size=0.2)
                    training_time = time.time() - start_time
                    
                    fixed_results[order] = {
                        'training_time': training_time,
                        'test_r2': results['test_r2'],
                        'test_mse': results['test_mse']
                    }
                    
                    print(f"   é˜¶æ•°{order}: RÂ²={results['test_r2']:.4f}, MSE={results['test_mse']:.6f}, æ—¶é—´={training_time:.3f}s")
                    
                except Exception as e:
                    print(f"   é˜¶æ•°{order}: å¤±è´¥ ({e})")
                    fixed_results[order] = {
                        'training_time': float('inf'),
                        'test_r2': -float('inf'),
                        'test_mse': float('inf')
                    }
            
            # æ™ºèƒ½é€‰æ‹©ç»“æœ
            intelligent_result = self.results[func_name]
            
            # æ‰¾åˆ°æœ€ä½³å›ºå®šé˜¶æ•°
            best_fixed_order = max(fixed_results.keys(), 
                                 key=lambda k: fixed_results[k]['test_r2'])
            best_fixed_result = fixed_results[best_fixed_order]
            
            comparison_results[func_name] = {
                'intelligent': intelligent_result,
                'fixed_results': fixed_results,
                'best_fixed_order': best_fixed_order,
                'best_fixed_result': best_fixed_result
            }
            
            print(f"   ğŸ§  æ™ºèƒ½é€‰æ‹©: é˜¶æ•°{intelligent_result['selected_order']}, RÂ²={intelligent_result['test_r2']:.4f}")
            print(f"   ğŸ¯ æœ€ä½³å›ºå®š: é˜¶æ•°{best_fixed_order}, RÂ²={best_fixed_result['test_r2']:.4f}")
            
            # æ¯”è¾ƒç»“æœ
            r2_improvement = intelligent_result['test_r2'] - best_fixed_result['test_r2']
            print(f"   ğŸ“ˆ RÂ²æå‡: {r2_improvement:+.4f}")
        
        return comparison_results
    
    def create_visualization(self, comparison_results):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Intelligent PCE Order Selection Analysis', fontsize=16, fontweight='bold')
        
        func_names = list(self.test_functions.keys())
        
        # 1. é˜¶æ•°é€‰æ‹©å‡†ç¡®æ€§
        ax1 = axes[0, 0]
        expected_orders = [self.test_functions[name]['expected_order'] for name in func_names]
        selected_orders = [self.results[name]['selected_order'] for name in func_names]
        
        x_pos = np.arange(len(func_names))
        width = 0.35
        
        ax1.bar(x_pos - width/2, expected_orders, width, label='Expected Order', alpha=0.7, color='skyblue')
        ax1.bar(x_pos + width/2, selected_orders, width, label='Selected Order', alpha=0.7, color='lightcoral')
        
        ax1.set_xlabel('Test Functions')
        ax1.set_ylabel('Polynomial Order')
        ax1.set_title('Order Selection Accuracy')
        ax1.set_xticks(x_pos)
        ax1.set_xticklabels(func_names, rotation=45)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. RÂ²åˆ†æ•°å¯¹æ¯”
        ax2 = axes[0, 1]
        intelligent_r2 = [self.results[name]['test_r2'] for name in func_names]
        best_fixed_r2 = [comparison_results[name]['best_fixed_result']['test_r2'] for name in func_names]
        
        ax2.bar(x_pos - width/2, intelligent_r2, width, label='Intelligent Selection', alpha=0.7, color='green')
        ax2.bar(x_pos + width/2, best_fixed_r2, width, label='Best Fixed Order', alpha=0.7, color='orange')
        
        ax2.set_xlabel('Test Functions')
        ax2.set_ylabel('RÂ² Score')
        ax2.set_title('Accuracy Comparison')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels(func_names, rotation=45)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. éçº¿æ€§å¼ºåº¦åˆ†æ
        ax3 = axes[0, 2]
        nonlinearity_scores = []
        for name in func_names:
            if self.results[name]['order_selection_results']:
                score = self.results[name]['order_selection_results']['theory_order']['nonlinearity_score']
                nonlinearity_scores.append(score)
            else:
                nonlinearity_scores.append(0)
        
        bars = ax3.bar(range(len(func_names)), nonlinearity_scores, alpha=0.7, color='purple')
        ax3.set_xlabel('Test Functions')
        ax3.set_ylabel('Nonlinearity Score')
        ax3.set_title('Function Complexity Analysis')
        ax3.set_xticks(range(len(func_names)))
        ax3.set_xticklabels(func_names, rotation=45)
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars, nonlinearity_scores):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{score:.2f}', ha='center', va='bottom', fontsize=9)
        
        # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”
        ax4 = axes[1, 0]
        selection_times = [self.results[name]['selection_time'] for name in func_names]
        training_times = [self.results[name]['training_time'] for name in func_names]
        
        ax4.bar(x_pos - width/2, selection_times, width, label='Order Selection Time', alpha=0.7, color='red')
        ax4.bar(x_pos + width/2, training_times, width, label='Training Time', alpha=0.7, color='blue')
        
        ax4.set_xlabel('Test Functions')
        ax4.set_ylabel('Time (seconds)')
        ax4.set_title('Time Analysis')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(func_names, rotation=45)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # 5. å†³ç­–æ–¹æ³•å¯¹æ¯”
        ax5 = axes[1, 1]
        methods = ['Theory', 'CV', 'AIC', 'BIC', 'Final']
        
        # æ”¶é›†æ‰€æœ‰å‡½æ•°çš„å†³ç­–æ•°æ®
        decision_data = []
        for name in func_names:
            if self.results[name]['order_selection_results']:
                results = self.results[name]['order_selection_results']
                decision_data.append([
                    results['theory_order']['suggested_order'],
                    results['cv_order']['best_order'],
                    results['ic_order']['best_aic_order'],
                    results['ic_order']['best_bic_order'],
                    results['optimal_order']
                ])
            else:
                decision_data.append([2, 2, 2, 2, 2])  # é»˜è®¤å€¼
        
        decision_data = np.array(decision_data).T
        
        for i, method in enumerate(methods):
            ax5.plot(range(len(func_names)), decision_data[i], 'o-', label=method, linewidth=2, markersize=6)
        
        ax5.set_xlabel('Test Functions')
        ax5.set_ylabel('Suggested Order')
        ax5.set_title('Decision Method Comparison')
        ax5.set_xticks(range(len(func_names)))
        ax5.set_xticklabels(func_names, rotation=45)
        ax5.legend()
        ax5.grid(True, alpha=0.3)
        
        # 6. æ€»ç»“ç»Ÿè®¡
        ax6 = axes[1, 2]
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        correct_selections = sum(1 for name in func_names 
                               if self.results[name]['selected_order'] == self.test_functions[name]['expected_order'])
        total_functions = len(func_names)
        accuracy_rate = correct_selections / total_functions * 100
        
        avg_r2_improvement = np.mean([
            self.results[name]['test_r2'] - comparison_results[name]['best_fixed_result']['test_r2']
            for name in func_names
        ])
        
        avg_selection_time = np.mean([self.results[name]['selection_time'] for name in func_names])
        
        # åˆ›å»ºç»Ÿè®¡å›¾è¡¨
        stats_labels = ['Selection\nAccuracy (%)', 'Avg RÂ²\nImprovement', 'Avg Selection\nTime (s)']
        stats_values = [accuracy_rate, avg_r2_improvement * 100, avg_selection_time]
        colors = ['lightgreen', 'lightblue', 'lightyellow']
        
        bars = ax6.bar(stats_labels, stats_values, color=colors, alpha=0.7)
        ax6.set_title('Summary Statistics')
        ax6.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, stats_values):
            height = bar.get_height()
            ax6.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{value:.2f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('intelligent_pce_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig
    
    def run_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸ¯ æ™ºèƒ½PCEé˜¶æ•°é€‰æ‹©æ¼”ç¤º")
        print("="*80)
        
        # 1. åˆ›å»ºæµ‹è¯•å‡½æ•°
        self.create_test_functions()
        
        # 2. æµ‹è¯•æ™ºèƒ½é˜¶æ•°é€‰æ‹©
        self.test_intelligent_order_selection()
        
        # 3. ä¸å›ºå®šé˜¶æ•°å¯¹æ¯”
        comparison_results = self.compare_with_fixed_orders()
        
        # 4. åˆ›å»ºå¯è§†åŒ–
        self.create_visualization(comparison_results)
        
        # 5. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(comparison_results)
        
        print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ç”Ÿæˆæ–‡ä»¶ï¼šintelligent_pce_analysis.png")
        
        return self.results, comparison_results
    
    def generate_summary_report(self, comparison_results):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“‹ æ™ºèƒ½PCEé˜¶æ•°é€‰æ‹©æ€»ç»“æŠ¥å‘Š")
        print("="*80)
        
        func_names = list(self.test_functions.keys())
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        correct_selections = sum(1 for name in func_names 
                               if self.results[name]['selected_order'] == self.test_functions[name]['expected_order'])
        total_functions = len(func_names)
        accuracy_rate = correct_selections / total_functions * 100
        
        avg_r2_improvement = np.mean([
            self.results[name]['test_r2'] - comparison_results[name]['best_fixed_result']['test_r2']
            for name in func_names
        ])
        
        avg_selection_time = np.mean([self.results[name]['selection_time'] for name in func_names])
        avg_training_time = np.mean([self.results[name]['training_time'] for name in func_names])
        
        print(f"ğŸ¯ æ€»ä½“æ€§èƒ½:")
        print(f"   é˜¶æ•°é€‰æ‹©å‡†ç¡®ç‡: {accuracy_rate:.1f}% ({correct_selections}/{total_functions})")
        print(f"   å¹³å‡RÂ²æå‡: {avg_r2_improvement:+.4f}")
        print(f"   å¹³å‡é€‰æ‹©æ—¶é—´: {avg_selection_time:.3f} ç§’")
        print(f"   å¹³å‡è®­ç»ƒæ—¶é—´: {avg_training_time:.3f} ç§’")
        
        print(f"\nğŸ“Š è¯¦ç»†ç»“æœ:")
        for name in func_names:
            result = self.results[name]
            expected = self.test_functions[name]['expected_order']
            selected = result['selected_order']
            r2_improvement = result['test_r2'] - comparison_results[name]['best_fixed_result']['test_r2']
            
            status = "âœ…" if selected == expected else "âš ï¸"
            print(f"   {name}: {status} æœŸæœ›{expected}é˜¶ â†’ é€‰æ‹©{selected}é˜¶, RÂ²æå‡{r2_improvement:+.4f}")
        
        print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
        print(f"   â€¢ æ™ºèƒ½é€‰æ‹©åœ¨{accuracy_rate:.0f}%çš„æƒ…å†µä¸‹é€‰æ‹©äº†æ­£ç¡®çš„é˜¶æ•°")
        print(f"   â€¢ å¹³å‡RÂ²æå‡{avg_r2_improvement*100:+.2f}%ï¼Œè¡¨æ˜æ™ºèƒ½é€‰æ‹©çš„æœ‰æ•ˆæ€§")
        print(f"   â€¢ é˜¶æ•°é€‰æ‹©æ—¶é—´çº¦{avg_selection_time:.2f}ç§’ï¼Œç›¸æ¯”è®­ç»ƒæ—¶é—´({avg_training_time:.2f}ç§’)æ˜¯å¯æ¥å—çš„å¼€é”€")
        print(f"   â€¢ å¯¹äºå¤æ‚éçº¿æ€§å‡½æ•°ï¼Œæ™ºèƒ½é€‰æ‹©èƒ½å¤Ÿè¯†åˆ«å¹¶æ¨èåˆé€‚çš„é˜¶æ•°")

def main():
    """ä¸»å‡½æ•°"""
    demo = IntelligentPCEDemo()
    results, comparison_results = demo.run_demo()
    return results, comparison_results

if __name__ == "__main__":
    main()
